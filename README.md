# TinyTensor
## 目标:实现一个支持 gpu 的深度学习框架.
## Dependencies
- ~~**Eigen**:一个矩阵库,可用于线性代数运算.~~ 目前已经不需要。
- **待续**
## TODO-LIST
- Tensor
- 封装
- 计算图,反向传播...
- 加速

## 项目运行
参见报告1结尾。

## 项目组织
使用 CMake 作为项目依赖管理.

## Tensor实现:
因为Tensor的维度不确定，因此底层使用1维数组实现，然后通过索引计算得到对应的元素。

目前 tensor 类的封装工作已经做好，索引已经完成，实现了在 gpu 和 cpu 之间的操作。暂时不支持张量之间的运算以及广播机制（wip）。

为了方便内存管理，使用了智能指针 `shared_ptr` 来管理一个 `DataStorage` 对象，这个对象封装了数组指针和设备，利用对象的销毁自动释放内存（RAII）。智能指针的引用计数机制可以保证多个 `Tensor` 对象共享同一个 `DataStorage` 对象，从而实现多个 `Tensor` 对象之间的赋值操作。

目前 `Tensor` 支持如下几种构造方式：
- `Tensor(std::vector<int> shape, std::string device = "cpu")` ，传入一个`vector`和设备名称，构造一个空的张量。
- 构造一个数组，然后传入头指针，构造一个`cpu`上的张量，形状可以自动推导（使用模板递归推导）。
- 复制构造函数，传入一个`Tensor`对象，构造一个与之相同的张量。




## 激活函数：
目前实现了 `ReLU` 和 `Sigmoid` 函数的正向及反向传播，同时支持 `cpu` 和 `gpu` 上的运算。

使用方法：先实例化一个激活函数对象，然后调用 `forward` 函数计算正向传播结果，调用 `backward` 函数计算反向传播结果，调用 `getName` 函数获取激活函数名称。  
正反向传播均需要传入一个`Tensor`对象。正向代表输入张量，反向代表下游梯度张量。  
在计算`sigmoid`的反向传播时，需要计算一次正向传播，这样会把正向传播的结果缓存起来，以便反向传播时使用。不要在正向传播之前调用反向传播函数，否则会抛出异常。

如果需要自定义激活函数，需要继承`ActivationFunction`基类并实现`forward`、`backward`、`getName`函数，并尽量实现核函数，以防不在同一个 device 上出现异常。